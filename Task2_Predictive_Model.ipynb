{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "083c0467",
   "metadata": {},
   "source": [
    "# Task 2 â€” Predicting Customer Holiday Purchases\n",
    "\n",
    "This notebook contains a complete, runnable workflow to prepare data, train a Random Forest model, evaluate results, and export outputs for the Forage submission. Edit `DATA_PATH` and the feature lists if your dataset uses different column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d92d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and plotting defaults\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "import joblib\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "print('Imports loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe4b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load data & quick EDA\n",
    "DATA_PATH = \"Customer_Booking.csv\"  # <-- change this if your file has a different name\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Data shape:', df.shape)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d234ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick checks (run these if you'd like more information)\n",
    "df.info()\n",
    "df.describe(include='all').T\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isna().sum().sort_values(ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c935de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define target and simple cleaning\n",
    "TARGET = \"BookedHoliday\"   # <-- change if your target column has another name\n",
    "\n",
    "# Convert target to numeric if needed\n",
    "if df[TARGET].dtype == object:\n",
    "    df[TARGET] = df[TARGET].map({'Yes': 1, 'No': 0})\n",
    "    df[TARGET] = df[TARGET].astype(int)\n",
    "\n",
    "# Drop obvious ID columns if present\n",
    "for col in ['CustomerID', 'ID', 'BookingID']:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=col, inplace=True)\n",
    "\n",
    "# Keep only rows with target present\n",
    "df = df[df[TARGET].notna()].reset_index(drop=True)\n",
    "print('Shape after cleaning:', df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Feature selection - update lists to match your data\n",
    "# Numeric features (edit)\n",
    "num_cols = [c for c in ['LeadTimeDays', 'Age', 'PastHolidayPurchases'] if c in df.columns]\n",
    "\n",
    "# Ordinal features (examples)\n",
    "ord_cols = [c for c in ['LoyaltyTier'] if c in df.columns]\n",
    "\n",
    "# Nominal categorical features\n",
    "cat_cols = [c for c in ['IncomeBand', 'DestinationType', 'TripType', 'BookingChannel', 'BookingOrigin'] if c in df.columns]\n",
    "\n",
    "print('Numeric:', num_cols)\n",
    "print('Ordinal:', ord_cols)\n",
    "print('Categorical:', cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae198e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Preprocessing and pipeline\n",
    "# Numeric transformer\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Ordinal transformer (define order if applicable)\n",
    "loyalty_order = ['Bronze', 'Silver', 'Gold', 'Platinum']  # edit to match your dataset\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ord', OrdinalEncoder(categories=[loyalty_order]) if ord_cols else 'passthrough')\n",
    "])\n",
    "\n",
    "# Categorical transformer\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_cols),\n",
    "    ('ord', ordinal_transformer, ord_cols),\n",
    "    ('cat', categorical_transformer, cat_cols)\n",
    "], remainder='drop', verbose_feature_names_out=False)\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "print('Pipeline created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c4154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Train/test split and baseline training\n",
    "X = df[num_cols + ord_cols + cat_cols]\n",
    "y = df[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:,1] if hasattr(clf.named_steps['rf'], 'predict_proba') else None\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, zero_division=0))\n",
    "print('Recall:', recall_score(y_test, y_pred, zero_division=0))\n",
    "print('F1:', f1_score(y_test, y_pred, zero_division=0))\n",
    "print('\\nClassification report:\\n', classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa0ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Confusion matrix and ROC curve\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xticks([0,1])\n",
    "plt.yticks([0,1])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i,j], ha=\"center\", va=\"center\", color=\"white\")\n",
    "plt.show()\n",
    "\n",
    "if y_proba is not None:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
    "    plt.plot([0,1],[0,1], '--', color='grey')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Feature importance (interpretable)\n",
    "preproc = clf.named_steps['preproc']\n",
    "rf = clf.named_steps['rf']\n",
    "\n",
    "feat_names = []\n",
    "feat_names += num_cols\n",
    "feat_names += ord_cols\n",
    "\n",
    "if cat_cols:\n",
    "    ohe = preproc.named_transformers_['cat'].named_steps['ohe']\n",
    "    ohe_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
    "    feat_names += ohe_names\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "fi = pd.DataFrame({'feature': feat_names, 'importance': importances})\n",
    "fi = fi.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "display(fi.head(20))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(fi['feature'].head(12)[::-1], fi['importance'].head(12)[::-1])\n",
    "plt.title('Top feature importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52abb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Save model and export predictions\n",
    "joblib.dump(clf, 'rf_pipeline_task2.joblib')\n",
    "preds = X_test.copy()\n",
    "preds['actual'] = y_test.values\n",
    "preds['pred'] = y_pred\n",
    "if y_proba is not None:\n",
    "    preds['probability'] = y_proba\n",
    "preds.to_csv('task2_test_predictions.csv', index=False)\n",
    "print('Saved rf_pipeline_task2.joblib and task2_test_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Build a concise summary for PowerPoint / Forage submission\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "top_features = fi['feature'].head(5).tolist()\n",
    "\n",
    "summary_text = f'''\n",
    "Model: Random Forest\n",
    "Accuracy: {acc:.3f}\n",
    "Precision: {prec:.3f}\n",
    "Recall: {rec:.3f}\n",
    "\n",
    "Top features:\n",
    "1) {top_features[0] if len(top_features)>0 else ''}\n",
    "2) {top_features[1] if len(top_features)>1 else ''}\n",
    "3) {top_features[2] if len(top_features)>2 else ''}\n",
    "4) {top_features[3] if len(top_features)>3 else ''}\n",
    "5) {top_features[4] if len(top_features)>4 else ''}\n",
    "'''\n",
    "print(summary_text)\n",
    "with open('task2_summary.txt','w') as f:\n",
    "    f.write(summary_text)\n",
    "print('Summary written to task2_summary.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20876d55",
   "metadata": {},
   "source": [
    "## Notes & Next Steps\n",
    "\n",
    "- If `BookedHoliday` is imbalanced, use `class_weight='balanced'` in RandomForest or try resampling (SMOTE).\n",
    "- For better interpretability consider using SHAP (`pip install shap`) and generating local explanations.\n",
    "- To tune the model, add a `GridSearchCV` cell (example commented below).\n",
    "\n",
    "### Optional: GridSearch snippet\n",
    "\n",
    "```python\n",
    "param_grid = {'rf__n_estimators':[100,200], 'rf__max_depth':[None,10,20]}\n",
    "search = GridSearchCV(clf, param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "print(search.best_params_)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
